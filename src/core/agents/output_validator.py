"""
OutputValidatorAgent - Valida resultado despu√©s de ejecutar.

Responsabilidad:
    Validar el resultado DESPU√âS de ejecutar (validaci√≥n sem√°ntica).

Caracter√≠sticas:
    - Modelo: gpt-4o (validaci√≥n robusta y precisa)
    - Ejecuciones: Despu√©s de cada ejecuci√≥n exitosa en E2B
    - Tool calling: NO
    - Costo: ~$0.002 por ejecuci√≥n
"""

from typing import Dict
import json
import time
from openai import AsyncOpenAI

from .base import BaseAgent, AgentResponse


class OutputValidatorAgent(BaseAgent):
    """Valida sem√°nticamente si la tarea se complet√≥ correctamente"""

    def __init__(self, openai_client: AsyncOpenAI):
        super().__init__("OutputValidator")
        self.client = openai_client
        self.model = "gpt-4o"

    async def execute(
        self,
        task: str,
        functional_context_before: Dict,
        functional_context_after: Dict,
        code_executed: str,
        execution_result: Dict
    ) -> AgentResponse:
        """
        Valida sem√°nticamente si la tarea se complet√≥ correctamente.

        Args:
            task: Tarea que se solicit√≥ resolver
            functional_context_before: Contexto funcional ANTES (truncado, sin config ni metadata)
            functional_context_after: Contexto funcional DESPU√âS (truncado, sin config ni metadata)
            code_executed: C√≥digo que se ejecut√≥ (para debugging)
            execution_result: Resultado completo de la ejecuci√≥n E2B (stderr, stdout, status, success)

        Returns:
            AgentResponse con:
                - valid: bool
                - reason: str (por qu√© es v√°lido o inv√°lido)
                - changes_detected: List[str] (keys modificadas/agregadas)
        """
        try:
            start_time = time.time()

            # üî• DEBUG: Log what OutputValidator received
            self.logger.info(f"üîç DEBUG - OutputValidator received:")
            self.logger.info(f"   Task: {task[:100]}...")
            self.logger.info(f"   functional_context_before keys: {list(functional_context_before.keys())}")
            self.logger.info(f"   functional_context_after keys: {list(functional_context_after.keys())}")
            self.logger.info(f"   functional_context_after full: {functional_context_after}")

            # Detectar cambios
            changes = self._detect_changes(functional_context_before, functional_context_after)

            self.logger.info(f"üîç DEBUG - Changes detected: {changes}")

            # Construir prompt
            prompt = self._build_prompt(
                task,
                functional_context_before,
                functional_context_after,
                changes,
                code_executed,
                execution_result
            )

            # Llamar a OpenAI
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "Eres un validador que verifica si las tareas se completaron correctamente. Respondes SOLO en JSON."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.3,
                response_format={"type": "json_object"},
                timeout=30.0  # 30 segundos timeout
            )

            execution_time_ms = (time.time() - start_time) * 1000

            # Parsear respuesta
            result = json.loads(response.choices[0].message.content)

            # Validar estructura
            required_keys = ["valid", "reason"]
            if not all(k in result for k in required_keys):
                raise ValueError(f"Respuesta inv√°lida, faltan keys: {required_keys}")

            # Agregar cambios detectados
            result["changes_detected"] = changes

            # Agregar metadata AI
            usage = response.usage
            tokens_input = usage.prompt_tokens if usage else 0
            tokens_output = usage.completion_tokens if usage else 0
            # Pricing gpt-4o: $2.50 per 1M input tokens, $10.00 per 1M output tokens
            cost_usd = (tokens_input * 2.50 / 1_000_000) + (tokens_output * 10.00 / 1_000_000)

            result["model"] = self.model
            result["tokens"] = {
                "input": tokens_input,
                "output": tokens_output
            }
            result["cost_usd"] = cost_usd

            if result["valid"]:
                self.logger.info(f"‚úÖ Output v√°lido: {result['reason']}")
            else:
                self.logger.warning(f"‚ùå Output inv√°lido: {result['reason']}")

            return self._create_response(
                success=True,
                data=result,
                execution_time_ms=execution_time_ms
            )

        except Exception as e:
            self.logger.error(f"Error en OutputValidator: {str(e)}")
            return self._create_response(
                success=False,
                error=str(e),
                execution_time_ms=0.0
            )

    def _detect_changes(self, before: Dict, after: Dict) -> list:
        """Detecta qu√© keys cambiaron entre before y after"""
        changes = []

        # Keys agregadas o modificadas
        for key in after.keys():
            if key not in before:
                changes.append(key)
            elif before[key] != after[key]:
                changes.append(key)

        return changes

    def _build_prompt(
        self,
        task: str,
        context_before: Dict,
        context_after: Dict,
        changes: list,
        generated_code: str = None,
        execution_result: Dict = None
    ) -> str:
        """Construye el prompt para validaci√≥n (diferente para DecisionNode vs ActionNode)"""

        # Detectar si es DecisionNode bas√°ndose en la tarea
        is_decision = any(keyword in task.lower() for keyword in ["decide", "eval√∫a", "verifica si", "check if", "determine if"])

        if is_decision:
            # ========== PROMPT PARA DECISIONNODE (ULTRA-SIMPLE) ==========
            return self._build_decision_prompt(task, context_after, changes)
        else:
            # ========== PROMPT PARA ACTIONNODE (ORIGINAL) ==========
            return self._build_action_prompt(task, context_before, context_after, changes, generated_code, execution_result)

    def _build_decision_prompt(self, task: str, context_after: Dict, changes: list) -> str:
        """Prompt ultra-simple para DecisionNodes"""

        # Buscar la key de decisi√≥n (deber√≠a estar en changes)
        decision_key = changes[0] if changes else "unknown"
        decision_value = context_after.get(decision_key, "N/A")

        # Extraer TODOS los datos del contexto que podr√≠an ser relevantes
        # (no solo los que matchean keywords, sino todo el contexto compactado)
        context_compact = self._compact_context(context_after, max_str_length=1500)

        prompt = f"""Esto es un DECISIONNODE. Tu trabajo: validar si la decisi√≥n es l√≥gica.

**Tarea:** {task}

**Decision tomada:**
- Key: '{decision_key}'
- Valor: '{decision_value}'

**Contexto disponible:**
{json.dumps(context_compact, indent=2, ensure_ascii=False)}

**Tu validaci√≥n:**
1. Lee la tarea para entender qu√© se est√° decidiendo
2. Mira el contexto para ver los datos relevantes
3. Verifica si la decisi√≥n ('{decision_value}') tiene sentido l√≥gico

- Un DecisionNode SOLO agrega la key de decisi√≥n, NO modifica otros datos (es normal)

Responde JSON:
{{
  "valid": true/false,
  "reason": "Explica por qu√© la decisi√≥n es correcta o incorrecta bas√°ndote en los datos"
}}

"""
        return prompt

    def _build_action_prompt(
        self,
        task: str,
        context_before: Dict,
        context_after: Dict,
        changes: list,
        generated_code: str = None,
        execution_result: Dict = None
    ) -> str:
        """Prompt original completo para ActionNodes (el que funcionaba bien)"""

        # Usar contexto compacto (no resumen agresivo)
        before_compact = self._compact_context(context_before, max_str_length=2000)
        after_compact = self._compact_context(context_after, max_str_length=2000)

        prompt = f"""Tu trabajo: Validar si la tarea se complet√≥ correctamente despu√©s de ejecutar el c√≥digo.

**Tarea solicitada:** {task}

**Contexto ANTES de ejecutar:**
{json.dumps(before_compact, indent=2, ensure_ascii=False)}

**Contexto DESPU√âS de ejecutar:**
{json.dumps(after_compact, indent=2, ensure_ascii=False)}

**Cambios detectados:** {changes if changes else "Ninguno"}
"""

        # Agregar informaci√≥n de ejecuci√≥n (stderr, stdout, status)
        if execution_result:
            status = execution_result.get("status", "unknown")
            prompt += f"""
**Resultado de la ejecuci√≥n:**
- Status: {status}
"""

            # Si hay stderr (error de Python), incluirlo
            stderr = execution_result.get("stderr", "")
            if stderr:
                prompt += f"""
- **Error (stderr):**
```
{stderr[:1000]}
```
"""

            # Si hay stdout (puede tener informaci√≥n √∫til)
            stdout = execution_result.get("stdout", "")
            if stdout:
                prompt += f"""
- **Output (stdout):**
```
{stdout[:500]}
```
"""

        # Agregar c√≥digo generado si est√° disponible (para mejor contexto)
        if generated_code:
            prompt += f"""
**C√≥digo que se ejecut√≥:**
```python
{generated_code}
```
"""

        prompt += """
Devuelve JSON:
{
  "valid": true/false,
  "reason": "Explicaci√≥n detallada de por qu√© es v√°lido o inv√°lido",
  "python_error": "Si hay error en stderr, extrae SOLO la l√≠nea del error espec√≠fico. Si no hay error, omite este campo."
}

üî¥ Es INV√ÅLIDO si:
1. **No hay cambios** ‚Üí El contexto no se modific√≥ (nada agregado/actualizado)
2. **Valores vac√≠os** ‚Üí Se agregaron keys pero est√°n vac√≠as ("", null, [], {}, 0 cuando deber√≠a haber un valor)
3. **Errores REALES** ‚Üí Hay keys "error"/"exception" con fallos REALES (crashes, timeouts)
4. **Tarea incompleta** ‚Üí La tarea ped√≠a X pero solo se hizo Y
5. **Valores sin sentido** ‚Üí Los valores agregados no tienen relaci√≥n con la tarea
6. **C√≥digo fall√≥** ‚Üí El c√≥digo crashe√≥ o no hizo nada √∫til
7. **Error en stderr** ‚Üí Hay un error de Python en stderr

üü¢ Es V√ÅLIDO si:
1. **Cambios relevantes** ‚Üí Se agregaron o modificaron datos importantes
2. **Valores correctos** ‚Üí Los valores agregados tienen sentido para la tarea
3. **Tarea completada** ‚Üí Todo lo que se pidi√≥ en la tarea est√° en el contexto
4. **Sin errores reales** ‚Üí No hay crashes ni fallos de ejecuci√≥n

‚ö†Ô∏è CASOS ESPECIALES:
- Si hay context['error'] pero es INFORMATIVO (ej: "No unread emails found"), eval√∫a si eso es un resultado LEG√çTIMO seg√∫n la tarea
- Distingue "c√≥digo fall√≥" (crash/timeout) vs "c√≥digo funcion√≥ pero no hab√≠a datos"
- Si la tarea era "leer email" y no hab√≠a emails, el error informativo es V√ÅLIDO

**IMPORTANTE - EVAL√öA SOLO LA EJECUCI√ìN ACTUAL:**
- NO especules sobre "qu√© pasar√≠a if..."
- SOLO eval√∫a: ¬øEsta ejecuci√≥n espec√≠fica funcion√≥ correctamente?
- S√© CR√çTICO pero bas√°ndote en RESULTADOS REALES, no potenciales bugs

üéØ Pregunta clave: ¬øEl c√≥digo hizo lo que se pidi√≥ EN ESTA EJECUCI√ìN espec√≠fica? S√≠/No
"""
        return prompt

    def _is_binary_string(self, value: str) -> bool:
        """
        Detecta si un string es binario/base64 vs texto legible.

        Args:
            value: String a analizar

        Returns:
            True si es binario/base64, False si es texto legible
        """
        # Sample primeros 500 chars para evitar analizar strings gigantes
        sample = value[:500]

        # 1. Detectar base64 (PDFs, im√°genes en base64)
        base64_chars = set('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=')
        if len(sample) > 100:
            base64_ratio = sum(c in base64_chars for c in sample) / len(sample)
            if base64_ratio > 0.95:  # >95% son caracteres base64
                return True

        # 2. Detectar caracteres no imprimibles (binarios)
        printable_ratio = sum(c.isprintable() or c.isspace() for c in sample) / len(sample)
        if printable_ratio < 0.80:  # <80% imprimibles = probablemente binario
            return True

        return False

    def _compact_context(self, context: Dict, max_str_length: int = 2000) -> Dict:
        """
        Compacta el contexto para el prompt SIN perder informaci√≥n estructural.

        Reglas:
        - Strings cortos (<2000 chars): enviar completos
        - Strings largos (>2000 chars): detectar si es binario o texto legible
          - Binario/base64: truncar
          - Texto legible: enviar completo (para validaci√≥n correcta)
        - Dicts/Lists: enviar estructura completa (sin resumir a "<dict with X items>")

        Args:
            context: Contexto a compactar
            max_str_length: Longitud m√°xima para strings antes de truncar (solo binarios)

        Returns:
            Contexto compactado pero con estructura real visible
        """
        compact = {}

        for key, value in context.items():
            # CASO 1: Strings
            if isinstance(value, str):
                if len(value) > max_str_length:
                    # Detectar si es binario/base64 o texto legible
                    if self._is_binary_string(value):
                        # Binario/base64: truncar
                        compact[key] = f"<binary data: {len(value)} chars, likely PDF/binary file>"
                    else:
                        # Texto legible: enviar completo para validaci√≥n correcta
                        compact[key] = value
                else:
                    # String corto, enviar completo
                    compact[key] = value

            # CASO 2: Dicts (mostrar estructura completa)
            elif isinstance(value, dict):
                if len(value) == 0:
                    compact[key] = {}
                else:
                    # Recursi√≥n para compactar valores internos
                    compact[key] = {
                        k: self._compact_value(v, max_str_length)
                        for k, v in value.items()
                    }

            # CASO 3: Lists (mostrar elementos reales)
            elif isinstance(value, list):
                if len(value) == 0:
                    compact[key] = []
                else:
                    # Compactar cada elemento
                    compact[key] = [
                        self._compact_value(item, max_str_length)
                        for item in value
                    ]

            # CASO 4: Otros tipos (int, float, bool, None)
            else:
                compact[key] = value

        return compact

    def _compact_value(self, value, max_str_length: int = 2000):
        """
        Compacta un valor individual (para usar en recursi√≥n).
        L√≠mite de recursi√≥n para evitar explosi√≥n de tokens.
        """
        if isinstance(value, str):
            if len(value) > max_str_length:
                # Detectar si es binario/base64 o texto legible
                if self._is_binary_string(value):
                    # Binario/base64: truncar
                    return f"<binary data: {len(value)} chars, likely PDF/binary file>"
                else:
                    # Texto legible: enviar completo para validaci√≥n correcta
                    return value
            return value

        elif isinstance(value, dict):
            if len(value) == 0:
                return {}
            # Recursi√≥n limitada (valores internos m√°s cortos)
            return {
                k: (v if not isinstance(v, (dict, list, str))
                    else self._compact_value(v, max_str_length=500))
                for k, v in value.items()
            }

        elif isinstance(value, list):
            if len(value) == 0:
                return []
            # Si la lista es muy larga (>20 items), mostrar primeros 10 + √∫ltimos 5
            if len(value) > 20:
                return [
                    *[self._compact_value(v, 500) for v in value[:10]],
                    f"... [{len(value) - 15} more items] ...",
                    *[self._compact_value(v, 500) for v in value[-5:]]
                ]
            return [self._compact_value(v, max_str_length=500) for v in value]

        else:
            return value
