"""
AnalysisValidatorAgent - Valida insights del DataAnalyzer.

Responsabilidad:
    Validar que los insights generados sean √∫tiles para resolver la tarea.

Caracter√≠sticas:
    - Modelo: gpt-4o-mini (validaci√≥n r√°pida)
    - Ejecuciones: Despu√©s de cada DataAnalyzer
    - Tool calling: NO
    - Costo: ~$0.0003 por validaci√≥n
"""

from typing import Dict
import json
import time
from openai import AsyncOpenAI

from .base import BaseAgent, AgentResponse


class AnalysisValidatorAgent(BaseAgent):
    """Valida que los insights del DataAnalyzer sean √∫tiles"""

    def __init__(self, openai_client: AsyncOpenAI):
        super().__init__("AnalysisValidator")
        self.client = openai_client
        self.model = "gpt-4o-mini"

    async def execute(
        self,
        task: str,
        functional_context_before: Dict,
        insights: Dict,
        analysis_code: str,
        execution_result: Dict
    ) -> AgentResponse:
        """
        Valida que los insights sean √∫tiles.

        Args:
            task: Tarea original a resolver
            functional_context_before: Contexto funcional ANTES del an√°lisis (truncado)
            insights: Insights generados por DataAnalyzer
            analysis_code: C√≥digo de an√°lisis ejecutado
            execution_result: Resultado completo de la ejecuci√≥n E2B

        Returns:
            AgentResponse con:
                - valid: bool
                - reason: str (por qu√© es v√°lido/inv√°lido)
                - suggestions: List[str] (qu√© mejorar)
                - model: str
                - tokens: dict
                - cost_usd: float
        """
        try:
            start_time = time.time()

            # Construir prompt
            prompt = self._build_prompt(
                task,
                functional_context_before,
                insights,
                analysis_code,
                execution_result
            )

            # Llamar a OpenAI
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "Eres un validador de an√°lisis de datos. Respondes SOLO en JSON."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.3,
                response_format={"type": "json_object"},
                timeout=30.0
            )

            execution_time_ms = (time.time() - start_time) * 1000

            # Parsear respuesta
            result = json.loads(response.choices[0].message.content)

            # Validar estructura
            required_keys = ["valid", "reason"]
            if not all(k in result for k in required_keys):
                raise ValueError(f"Respuesta inv√°lida, faltan keys: {required_keys}")

            # Agregar metadata AI
            usage = response.usage
            tokens_input = usage.prompt_tokens if usage else 0
            tokens_output = usage.completion_tokens if usage else 0
            cost_usd = (tokens_input * 0.150 / 1_000_000) + (tokens_output * 0.600 / 1_000_000)

            result["model"] = self.model
            result["tokens"] = {
                "input": tokens_input,
                "output": tokens_output
            }
            result["cost_usd"] = cost_usd

            if result["valid"]:
                self.logger.info(f"‚úÖ Insights v√°lidos: {result['reason']}")
            else:
                self.logger.warning(f"‚ùå Insights inv√°lidos: {result['reason']}")

            return self._create_response(
                success=True,
                data=result,
                execution_time_ms=execution_time_ms
            )

        except Exception as e:
            self.logger.error(f"Error en AnalysisValidator: {str(e)}")
            return self._create_response(
                success=False,
                error=str(e),
                execution_time_ms=0.0
            )

    def _build_prompt(
        self,
        task: str,
        functional_context_before: Dict,
        insights: Dict,
        analysis_code: str,
        execution_result: Dict
    ) -> str:
        """Construye el prompt para validaci√≥n"""

        # Mostrar solo primeras/√∫ltimas l√≠neas del c√≥digo
        code_lines = analysis_code.split("\n")
        if len(code_lines) > 20:
            code_preview = "\n".join(code_lines[:10]) + "\n...\n" + "\n".join(code_lines[-5:])
        else:
            code_preview = analysis_code

        # Extraer info relevante del execution_result
        execution_status = "success" if execution_result.get("success") else "failed"
        execution_error = execution_result.get("error", "")
        execution_stdout = execution_result.get("_stdout", "")[:500]  # Primeros 500 chars

        prompt = f"""Tu trabajo: Validar si los insights generados son √∫tiles para resolver la tarea.

**Tarea original:** {task}

**Contexto funcional (antes del an√°lisis):**
{json.dumps(functional_context_before, indent=2, ensure_ascii=False)}

**Insights generados:**
{json.dumps(insights, indent=2, ensure_ascii=False)}

**C√≥digo de an√°lisis ejecutado:**
```python
{code_preview}
```

**Resultado de ejecuci√≥n:**
- Status: {execution_status}
- Error: {execution_error if execution_error else "None"}
- Stdout (primeros 500 chars): {execution_stdout}
"""

        prompt += """
Devuelve JSON:
{
  "valid": true/false,
  "reason": "Explicaci√≥n breve de por qu√© es v√°lido o inv√°lido",
  "suggestions": ["sugerencia 1", "sugerencia 2"]  // solo si invalid
}

üî¥ Los insights son INV√ÅLIDOS SOLO si:
1. **Crash de ejecuci√≥n** ‚Üí El c√≥digo crashe√≥ con traceback de Python (contiene "Traceback", "Error:", stack trace)
2. **Sin output estructurado** ‚Üí No retorn√≥ ning√∫n dict ni JSON parseado, solo un string sin estructura
3. **Error expl√≠cito SIN metadata** ‚Üí Solo dice {"error": "..."} sin ninguna info adicional √∫til

üü¢ Los insights son V√ÅLIDOS si:
1. **Retorna dict estructurado** ‚Üí Aunque sea m√≠nimo como {"type": "pdf"} es v√°lido
2. **Describe algo sobre la data** ‚Üí Aunque sea parcial o b√°sico, si describe algo es v√°lido
3. **Valores falsy son V√ÅLIDOS** ‚Üí 0, False, [], {} son informaci√≥n √öTIL (ej: "pages": 0 significa PDF vac√≠o)
4. **Type unknown CON contexto** ‚Üí Si explica por qu√©: {"type": "unknown", "reason": "corrupted"} es V√ÅLIDO
5. **Error CON metadata parcial** ‚Üí {"error": "...", "partial_info": {...}} es V√ÅLIDO (dio algo de info)

‚ö†Ô∏è **S√â PERMISIVO - Los insights son DESCRIPTIVOS, NO RESOLUTIVOS:**
- ‚ùå NO rechaces por "falta de detalles" ‚Üí Insights parciales/m√≠nimos son OK
- ‚ùå NO rechaces por "metadata vac√≠a" si tiene valores falsy (0, False, [])
- ‚ùå NO rechaces por "type unknown" si explica el motivo
- ‚ùå NO rechaces por "deber√≠a incluir m√°s info" ‚Üí NO exijas exhaustividad
- ‚úÖ Acepta an√°lisis m√≠nimos pero correctos
- ‚úÖ Distingue "c√≥digo crashe√≥" (INV√ÅLIDO) vs "data vac√≠a/corrupta" (V√ÅLIDO)

**Ejemplos de insights V√ÅLIDOS (acepta estos)**:
‚úÖ {"type": "pdf", "pages": 0} ‚Üí Describe que el PDF est√° vac√≠o (falsy value OK)
‚úÖ {"type": "email", "attachments": []} ‚Üí Describe que no hay attachments (lista vac√≠a OK)
‚úÖ {"type": "unknown", "reason": "file corrupted"} ‚Üí Explica por qu√© no detect√≥ (OK)
‚úÖ {"type": "pdf", "size": 1024} ‚Üí M√≠nimo pero √∫til (OK)
‚úÖ {"type": "csv", "rows": 100} ‚Üí B√°sico pero suficiente (OK)

**Ejemplos de insights INV√ÅLIDOS (rechaza SOLO estos)**:
‚ùå {"error": "Traceback (most recent call last)..."} ‚Üí C√≥digo crashe√≥ SIN metadata
‚ùå "No data found" ‚Üí String sin estructura (no es dict)
‚ùå {} ‚Üí Dict completamente vac√≠o sin ninguna info
‚ùå {"error": "Failed"} ‚Üí Error gen√©rico sin contexto ni metadata

üéØ Pregunta clave: ¬øEl an√°lisis se ejecut√≥ correctamente y retorn√≥ ALGUNA informaci√≥n estructurada?

**Tu reason debe explicar**:
- Si V√ÅLIDO: "Los insights describen [X] sobre la data, suficiente para el CodeGenerator"
- Si INV√ÅLIDO: "El c√≥digo crashe√≥ con error: [traceback]" o "No retorn√≥ estructura"

**NO digas** (evitar estas frases que son demasiado estrictas):
‚ùå "Falta informaci√≥n sobre..."
‚ùå "Metadata insuficiente..."
‚ùå "Deber√≠a incluir m√°s detalles sobre..."

Recuerda: Tu trabajo es validar que el AN√ÅLISIS funcion√≥, no que sea exhaustivo o perfecto.
"""
        return prompt
